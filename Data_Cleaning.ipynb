{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNH/pNFXYlHF/RqB2SDNr+x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ammad19/AI-course-exercises/blob/master/Data_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvlHXZcNuw5F"
      },
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "from numpy import nan as NA\r\n",
        "\r\n",
        "data = pd.DataFrame([[1., 6.5, NA], [1., NA, NA], \r\n",
        "                     [NA, NA, NA], [NA, 6.5, NA]], \r\n",
        "                    columns = list('abc'))\r\n",
        "display(data)\r\n",
        "#remoe all rows that have null values\r\n",
        "cleaned = data.dropna()\r\n",
        "\r\n",
        "#how = all = remove rows only all data is NaN\r\n",
        "#cleaned = data.dropna(how='all')\r\n",
        "#display(cleaned)\r\n",
        "print() # blank line\r\n",
        "#print(cleaned)\r\n",
        "\r\n",
        "#Passing how='all' will only drop rows that are all NA:\r\n",
        "#data.dropna(how='all')\r\n",
        "\r\n",
        "# dropping columns that have all null values\r\n",
        "data.dropna(axis=1)\r\n",
        "data.dropna(axis=1, how='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPCsgPODu9BP"
      },
      "source": [
        "#filling of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1j0oq7au_KO"
      },
      "source": [
        "import numpy as np\r\n",
        "from numpy import nan as NA\r\n",
        "df = pd.DataFrame(np.random.randn(7, 3))\r\n",
        "#print(df)\r\n",
        "df.iloc[:4, 1] = NA\r\n",
        "df.iloc[:2, 2] = NA\r\n",
        "#display(df)\r\n",
        "#Calling fillna with a dict, you can use a different fill value for each column:\r\n",
        "#df.fillna(1.5)\r\n",
        "#display(df)\r\n",
        "\r\n",
        "# column number 1 will be filled with 0.5\r\n",
        "# column number 2 will be fileld with 0\r\n",
        "#df = df.fillna({1: 0.5, 2: 0})\r\n",
        "#display(df)\r\n",
        "\r\n",
        "# fill  not values from left column (axis=0 means from top row)\r\n",
        "#df = df.fillna(method='ffill')\r\n",
        "#display(df)\r\n",
        "\r\n",
        "#df = df.fillna(method='ffill', axis = 1)\r\n",
        "#display(df)\r\n",
        "df = df.fillna(method='ffill', limit=1, axis=1)\r\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqiqI1W-vD1x"
      },
      "source": [
        "#removing duplicates\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "data = pd.DataFrame({'k1': ['one', 'two'] * 3 + ['two'],\r\n",
        "                     'k2': [1, 1, 2, 3, 3, 4, 4]} )\r\n",
        "#display(data)\r\n",
        "#data.duplicated()\r\n",
        "#data = data.drop_duplicates()\r\n",
        "#display(data)\r\n",
        "data['v1'] = ['one', 'two', 'one', 'four', 'one', 'six', 'two']\r\n",
        "#display(data)\r\n",
        "display(data[ ['k1','v1'] ])\r\n",
        "data = data.drop_duplicates(['k1', 'v1'])\r\n",
        "\r\n",
        "display(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkwOOKmNvKom"
      },
      "source": [
        "#replacing values\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "df = pd.DataFrame(np.random.randn(7, 3))\r\n",
        "\r\n",
        "df.iloc[:4, 1] = np.nan\r\n",
        "df.iloc[:2, 2] = np.nan\r\n",
        "#display(df)\r\n",
        "df = df.replace(np.nan , -999)\r\n",
        "display(df)\r\n",
        "#df = df.replace(-999 , -9)\r\n",
        "display(df)\r\n",
        "df =df.replace([-999, -9], [101, 0])\r\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5KhRHHsvRyz"
      },
      "source": [
        "#function mapping\r\n",
        "data = pd.DataFrame(np.arange(12).reshape((3, 4)),\r\n",
        "        index=['Ohio', 'Colorado', 'New York'],\r\n",
        "        columns=['one', 'two', 'three', 'four'])\r\n",
        "\r\n",
        "#display(data)\r\n",
        "transform = lambda x: x[:4].upper()\r\n",
        "data.index = data.index.map(transform)\r\n",
        "display(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGmXRok5vY4A"
      },
      "source": [
        "#detecting & filtering\r\n",
        "data = pd.DataFrame(np.random.randn(1000, 4))\r\n",
        "data.describe()\r\n",
        "col = data[2]\r\n",
        "#print(col)\r\n",
        "#col[np.abs(col) > 3]\r\n",
        "#To select all rows having a value exceeding 3 or –3, \r\n",
        "#you can use the 'any' method on a boolean DataFrame:\r\n",
        "#any method will check all cells \r\n",
        "outliers = data[(np.abs(data) > 3).any(1)]\r\n",
        "print(len(outliers), len(data))\r\n",
        "outliers\r\n",
        "# check the difference\r\n",
        "#print(data)\r\n",
        "#data[(np.abs(data) > 3)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgpL_dprvf08"
      },
      "source": [
        "#permutation & sampling\r\n",
        "# Permuting (randomly reordering)\r\n",
        "# a Series or the rows in a DataFrame\r\n",
        "df = pd.DataFrame(np.arange(5 * 4).reshape((5, 4)))\r\n",
        "#print( df.shape )\r\n",
        "sampler = np.random.permutation(4)\r\n",
        "print(sampler)\r\n",
        "#df = df[sampler]\r\n",
        "display(df)\r\n",
        "df.take(sampler)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4sXxGpKvotX"
      },
      "source": [
        "#Regular Expressions\r\n",
        "import re\r\n",
        "text = \"foo    bar\\t baz \\tqux\"\r\n",
        "#normal split = text.split()\r\n",
        "#re.split('\\s+', text) # spliting based on whitespaces\r\n",
        "#text.split(\" \")\r\n",
        "#['foo', 'bar', 'baz', 'qux']\r\n",
        "# compile once to use again and again and save time\r\n",
        "rgx = re.compile('\\s+')\r\n",
        "rgx.split(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umZobMxivwY7"
      },
      "source": [
        "#Vectorized String Functions in pandas\r\n",
        "import re\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "data = {'Dave': 'dave@google.com', 'Steve': 'steve@gmail.com',\r\n",
        "'Rob': 'rob@gmail.com', 'Wes': np.nan}\r\n",
        "data = [\"simpleEmail@email.com\",   \"simple.email@email.com\",  \r\n",
        "        \"plus+symbol@email.com\",   \"dash-symbol@email.com\",  \r\n",
        "     \"q@email.com\",   \r\n",
        "    \"“unusual”@email.com\",   \"dash-symbol@email-dash.com\",   \"test@emailServer\",  \r\n",
        "  \"” “@email.com\",   \"user@[IPv6:2001:DB8::1]\",   \r\n",
        "  \"example@localhost\",   \"example@s.solutions\",   \r\n",
        "  \"12345@email.com\"]   \r\n",
        "\r\n",
        "data = pd.Series(data)\r\n",
        "display(data)\r\n",
        "pattern = '([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\\\.([A-Z]{2,4})'\r\n",
        "#data.str.findall(pattern, flags=re.IGNORECASE)\r\n",
        "matches = data[data.str.match(pattern, flags=re.IGNORECASE)]\r\n",
        "matches"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}